{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# En una celda de Google Colab, copia y pega esto:\n",
    "\n",
    "# 1. Instalar kaggle CLI\n",
    "!pip install -q kaggle\n",
    "\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import zipfile\n",
    "import random\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "from IPython.display import display\n",
    "\n",
    "# Configuraci√≥n\n",
    "CLASSES = ['commercial', 'commercial_electrical', 'private', 'private_electrical', 'rentable']\n",
    "DATA_DIR = Path('data')\n",
    "GENERATED_DIR = DATA_DIR / 'license_plates' / 'generated'\n",
    "DATASET_DIR = DATA_DIR / 'dataset'\n",
    "\n",
    "# 0. Verificar si ya existe el dataset procesado\n",
    "if (DATASET_DIR / 'train').exists() and GENERATED_DIR.exists():\n",
    "    print(\"‚úÖ Dataset ya preparado completamente. Omite descarga y particionado.\")\n",
    "else:\n",
    "    # 1. Configurar Kaggle API manualmente (solo si no existe el archivo)\n",
    "    kaggle_user = 'agustinmercado'\n",
    "    kaggle_key ='18fb1e0944022e74a3741e7a989519de'\n",
    "\n",
    "    os.makedirs(Path.home() / \".kaggle\", exist_ok=True)\n",
    "    kaggle_json_path = Path.home() / \".kaggle\" / \"kaggle.json\"\n",
    "    with open(kaggle_json_path, \"w\") as f:\n",
    "        json.dump({\"username\": kaggle_user, \"key\": kaggle_key}, f)\n",
    "    os.chmod(kaggle_json_path, 0o600)\n",
    "\n",
    "    # 2. Descargar dataset si no est√°\n",
    "    if not GENERATED_DIR.exists():\n",
    "        print(\"‚¨áÔ∏è Descargando dataset...\")\n",
    "        os.makedirs(DATA_DIR, exist_ok=True)\n",
    "        subprocess.run([\n",
    "            \"kaggle\", \"datasets\", \"download\", \"-d\", \"abtexp/synthetic-indian-license-plates\",\n",
    "            \"-p\", str(DATA_DIR)\n",
    "        ], check=True)\n",
    "\n",
    "        with zipfile.ZipFile(DATA_DIR / \"synthetic-indian-license-plates.zip\", \"r\") as zip_ref:\n",
    "            zip_ref.extractall(DATA_DIR / \"license_plates\")\n",
    "    else:\n",
    "        print(\"üì¶ Dataset ya descomprimido.\")\n",
    "\n",
    "    # 3. Crear estructura de carpetas\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        for cls in CLASSES:\n",
    "            os.makedirs(DATASET_DIR / split / cls, exist_ok=True)\n",
    "\n",
    "    # 4. Recolectar im√°genes\n",
    "    all_images = {cls: [] for cls in CLASSES}\n",
    "    for state_path in GENERATED_DIR.iterdir():\n",
    "        if not state_path.is_dir():\n",
    "            continue\n",
    "        for cls in CLASSES:\n",
    "            class_path = state_path / cls\n",
    "            if class_path.exists():\n",
    "                all_images[cls].extend(class_path.glob(\"*.png\"))\n",
    "\n",
    "    # 5. Split estratificado\n",
    "    for cls, img_list in all_images.items():\n",
    "        if not img_list:\n",
    "            print(f\"‚ö†Ô∏è No hay im√°genes para la clase {cls}\")\n",
    "            continue\n",
    "\n",
    "        random.shuffle(img_list)\n",
    "        total = len(img_list)\n",
    "        train_count = int(total * 0.8)\n",
    "        val_count = int(total * 0.1)\n",
    "\n",
    "        for i, img_path in enumerate(img_list):\n",
    "            if i < train_count:\n",
    "                dest = DATASET_DIR / 'train' / cls / img_path.name\n",
    "            elif i < train_count + val_count:\n",
    "                dest = DATASET_DIR / 'val' / cls / img_path.name\n",
    "            else:\n",
    "                dest = DATASET_DIR / 'test' / cls / img_path.name\n",
    "            shutil.copy2(img_path, dest)\n",
    "\n",
    "    print(\"‚úÖ Dataset preparado correctamente.\")\n",
    "\n",
    "# 6. Mostrar resumen\n",
    "print(\"\\nüìä Resumen del dataset:\")\n",
    "for split in ['train', 'val', 'test']:\n",
    "    for cls in CLASSES:\n",
    "        count = len(list((DATASET_DIR / split / cls).glob(\"*\")))\n",
    "        print(f\"{split}/{cls}: {count}\")\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import zipfile\n",
    "import random\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "from IPython.display import display\n",
    "\n",
    "# Configuraci√≥n\n",
    "CLASSES = ['commercial', 'commercial_electrical', 'private', 'private_electrical', 'rentable']\n",
    "DATA_DIR = Path('data')\n",
    "GENERATED_DIR = DATA_DIR / 'license_plates' / 'generated'\n",
    "DATASET_DIR = DATA_DIR / 'dataset'\n",
    "\n",
    "# 0. Verificar si ya existe el dataset procesado\n",
    "if (DATASET_DIR / 'train').exists() and GENERATED_DIR.exists():\n",
    "    print(\"‚úÖ Dataset ya preparado completamente. Omite descarga y particionado.\")\n",
    "else:\n",
    "    # 1. Configurar Kaggle API manualmente (solo si no existe el archivo)\n",
    "    kaggle_user = input(\"üëâ Ingres√° tu KAGGLE_USERNAME: \").strip()\n",
    "    kaggle_key = input(\"üîë Ingres√° tu KAGGLE_KEY: \").strip()\n",
    "\n",
    "    os.makedirs(Path.home() / \".kaggle\", exist_ok=True)\n",
    "    kaggle_json_path = Path.home() / \".kaggle\" / \"kaggle.json\"\n",
    "    with open(kaggle_json_path, \"w\") as f:\n",
    "        json.dump({\"username\": kaggle_user, \"key\": kaggle_key}, f)\n",
    "    os.chmod(kaggle_json_path, 0o600)\n",
    "\n",
    "    # 2. Descargar dataset si no est√°\n",
    "    if not GENERATED_DIR.exists():\n",
    "        print(\"‚¨áÔ∏è Descargando dataset...\")\n",
    "        os.makedirs(DATA_DIR, exist_ok=True)\n",
    "        subprocess.run([\n",
    "            \"kaggle\", \"datasets\", \"download\", \"-d\", \"abtexp/synthetic-indian-license-plates\",\n",
    "            \"-p\", str(DATA_DIR)\n",
    "        ], check=True)\n",
    "\n",
    "        with zipfile.ZipFile(DATA_DIR / \"synthetic-indian-license-plates.zip\", \"r\") as zip_ref:\n",
    "            zip_ref.extractall(DATA_DIR / \"license_plates\")\n",
    "    else:\n",
    "        print(\"üì¶ Dataset ya descomprimido.\")\n",
    "\n",
    "    # 3. Crear estructura de carpetas\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        for cls in CLASSES:\n",
    "            os.makedirs(DATASET_DIR / split / cls, exist_ok=True)\n",
    "\n",
    "    # 4. Recolectar im√°genes\n",
    "    all_images = {cls: [] for cls in CLASSES}\n",
    "    for state_path in GENERATED_DIR.iterdir():\n",
    "        if not state_path.is_dir():\n",
    "            continue\n",
    "        for cls in CLASSES:\n",
    "            class_path = state_path / cls\n",
    "            if class_path.exists():\n",
    "                all_images[cls].extend(class_path.glob(\"*.png\"))\n",
    "\n",
    "    # 5. Split estratificado\n",
    "    for cls, img_list in all_images.items():\n",
    "        if not img_list:\n",
    "            print(f\"‚ö†Ô∏è No hay im√°genes para la clase {cls}\")\n",
    "            continue\n",
    "\n",
    "        random.shuffle(img_list)\n",
    "        total = len(img_list)\n",
    "        train_count = int(total * 0.8)\n",
    "        val_count = int(total * 0.1)\n",
    "\n",
    "        for i, img_path in enumerate(img_list):\n",
    "            if i < train_count:\n",
    "                dest = DATASET_DIR / 'train' / cls / img_path.name\n",
    "            elif i < train_count + val_count:\n",
    "                dest = DATASET_DIR / 'val' / cls / img_path.name\n",
    "            else:\n",
    "                dest = DATASET_DIR / 'test' / cls / img_path.name\n",
    "            shutil.copy2(img_path, dest)\n",
    "\n",
    "    print(\"‚úÖ Dataset preparado correctamente.\")\n",
    "\n",
    "# 6. Mostrar resumen\n",
    "print(\"\\nüìä Resumen del dataset:\")\n",
    "for split in ['train', 'val', 'test']:\n",
    "    for cls in CLASSES:\n",
    "        count = len(list((DATASET_DIR / split / cls).glob(\"*\")))\n",
    "        print(f\"{split}/{cls}: {count}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. librer√≠as necesarias para construir, entrenar y evaluar el modelo CNN MobileNetV2, adem√°s de herramientas para manejo de datos, visualizaci√≥n y m√©tricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Definicion de Hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = (128, 512)\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 20\n",
    "LR_MOBILENET = 1e-4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Verificacion de rutas de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "base_dir = 'data/dataset'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "val_dir = os.path.join(base_dir, 'val')\n",
    "test_dir = os.path.join(base_dir, 'test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Deteccion atuoamticas de clases "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def get_classes_from_directory(directory):\n",
    "    return sorted([\n",
    "        d for d in os.listdir(directory)\n",
    "        if os.path.isdir(os.path.join(directory, d)) and not d.startswith('.')\n",
    "    ])\n",
    "\n",
    "CLASSES = get_classes_from_directory(train_dir)\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "\n",
    "print(CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Aumentacion de datos para entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=5,\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    shear_range=0.05,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=False,  # Placas no deber√≠an reflejarse\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_test_datagen = ImageDataGenerator(rescale=1./255, dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## train_datagen = ImageDataGGenerator(..)\n",
    "\n",
    "este generador solo usa el cojunto den entrenamiento\n",
    "\n",
    "Argumentos utilizados: \n",
    "\n",
    "| Par√°metro                     | Descripci√≥n                                                                                                   |\n",
    "| ----------------------------- | ------------------------------------------------------------------------------------------------------------- |\n",
    "| `rescale=1./255`              | Escala los p√≠xeles de \\[0, 255] a \\[0, 1], necesario para redes neuronales.                                   |\n",
    "| `rotation_range=5`           | Gira la imagen aleatoriamente entre -5¬∞ y 5¬∞.                                                               |\n",
    "| `width_shift_range=0.2`       | Desplaza la imagen horizontalmente hasta un 20% del ancho.                                                    |\n",
    "| `height_shift_range=0.2`      | Desplaza la imagen verticalmente hasta un 20% de la altura.                                                   |\n",
    "| `shear_range=0.15`            | Aplica una distorsi√≥n en forma de cizalla (shear), inclinando la imagen.                                      |\n",
    "| `zoom_range=0.2`              | Aplica zoom aleatorio hasta un 20% m√°s o menos.                                                               |\n",
    "| `horizontal_flip=false`        | para la no asemitria.                                     |\n",
    "| `fill_mode='nearest'`         | Cuando se hace una transformaci√≥n que genera espacios vac√≠os, los rellena con el valor del p√≠xel m√°s cercano. |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "basicamente lo que hace toma una imagen original y crea nuevas versiones modificadas aleatoriamente en cada epoca dele entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## val_test_datagen = ImageDataGenerator(..)\n",
    "\n",
    "este lo utilizamos para validacion y test . no aplicamos ningun tipo de aumneto, ya que no queremos alterar los datos al evaluar el rendimiento del modelo \n",
    "\n",
    "1. rescale=1/255 -> normaliza los pixeles\n",
    "\n",
    "2. dtype='float32' -> mismo tipo de dato del anterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Generadores de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    classes=CLASSES\n",
    ")\n",
    "\n",
    "val_generator = val_test_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    classes=CLASSES\n",
    ")\n",
    "\n",
    "test_generator = val_test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    "    classes=CLASSES\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "esta porcion de codigo leen las imagenes de disco , le asginana etiquetas segun la clase que es, la transforma y la entraga en lotes a la red neuronal para el entrenamiento la validacion y el testeo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Calculos de pesos por clases para balancer el entranamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Calcular class_weight\n",
    "class_weights_array = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_generator.classes),\n",
    "    y=train_generator.classes\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights_array))\n",
    "print(\"Pesos por clase:\", class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este c√≥digo calcula pesos para cada clase seg√∫n su frecuencia en los datos de entrenamiento, de forma que las clases menos frecuentes tengan un peso mayor. Esto ayuda a que el modelo no se sesgue hacia las clases m√°s comunes.\n",
    "\n",
    "1. compute_class_weight con 'balanced' genera esos pesos autom√°ticamente.\n",
    "\n",
    "2. class_weights es un diccionario {clase: peso} que luego se usa en el entrenamiento para darle m√°s importancia a las clases minoritarias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Construccion del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "se carga el modelo preentrenado (sin la capa de clasificacion final) con pesos de imageNet. congelamosla capa convulacional para usarlo como extratctor de caracteristicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "outputs = Dense(NUM_CLASSES, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. creamos un tensor de entrada con la forma de la imagen \n",
    "\n",
    "2. pasamos esa entrada por el modelo base para extraer las caractetitsitcas \n",
    "\n",
    "3. aplicamos **GolbalAvergaePooling** para convertir el mapa de caracteristicas 2d un en vector 1D para poder pasarla a la capa siguiente\n",
    "\n",
    "4. creamos la capa de salida con **NUM_CLASSES** neuronaes, con activacion softmax para clasificacion multiclase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model = Model(inputs, outputs, name=\"MobileNetV2\") # creamos el modelo entero con entrada y salida definida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compilo el modelo con : \n",
    "\n",
    "1. optimizador Adam\n",
    "\n",
    "2. la funcion de perdida es entropia cruzada \n",
    "\n",
    "\n",
    "3. metrica principal es el **accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=LR_MOBILENET),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ![Descripci√≥n de la imagen](./img/mobile.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OBS: SOLO LA CAPA DENSE ES ENTRENABLE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.  Callbacks para control del entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2),\n",
    "    ModelCheckpoint('output/best_mobilenet.h5', save_best_only=True, monitor='val_accuracy'),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. EarlyStopping\n",
    "\n",
    "    - Funci√≥n: Detiene el entrenamiento si no mejora durante 3 √©pocas.\n",
    "\n",
    "    - Ventaja: Evita el sobreentrenamiento y ahorra tiempo.\n",
    "\n",
    "    - restore_best_weights=True: Recupera los mejores pesos al final.\n",
    "\n",
    "2. ReduceLROnPlateau\n",
    "\n",
    "    - Funci√≥n: Reduce el learning rate si no mejora en 2 √©pocas.\n",
    "\n",
    "    - Ventaja: Permite ajustes finos al estancarse el modelo.\n",
    "\n",
    "    - factor=0.5: Reduce el LR al 50% del actual.\n",
    "\n",
    "3. ModelCheckpoint\n",
    "\n",
    "    - Funci√≥n: Guarda el modelo cada vez que mejora la precisi√≥n en validaci√≥n (val_accuracy).\n",
    "\n",
    "    - Ventaja: Conserva autom√°ticamente la mejor versi√≥n del modelo.\n",
    "\n",
    "    - save_best_only=True: Solo guarda si mejora respecto al anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Entranamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Entrenamiento\n",
    "print(\"\\nEntrenando MobileNetV2...\")\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=callbacks,\n",
    "    class_weight=class_weights,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11 . Visualizacion, Prediccion y evaluacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Gr√°ficos\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Entrenamiento')\n",
    "plt.plot(history.history['val_accuracy'], label='Validaci√≥n')\n",
    "plt.title('Precisi√≥n - MobileNetV2')\n",
    "plt.ylabel('Precisi√≥n')\n",
    "plt.xlabel('√âpoca')\n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Entrenamiento')\n",
    "plt.plot(history.history['val_loss'], label='Validaci√≥n')\n",
    "plt.title('P√©rdida - MobileNetV2')\n",
    "plt.ylabel('P√©rdida')\n",
    "plt.xlabel('√âpoca')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/MobileNetV2_history.png')\n",
    "plt.close()\n",
    "\n",
    "# Evaluaci√≥n\n",
    "y_pred = model.predict(test_generator)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = test_generator.classes\n",
    "labels = list(test_generator.class_indices.values())\n",
    "target_names = list(test_generator.class_indices.keys())\n",
    "print(\"\\nClassification Report for MobileNetV2:\")\n",
    "print(classification_report(\n",
    "    y_true, y_pred_classes,\n",
    "    labels=labels,\n",
    "    target_names=target_names,\n",
    "    digits=4,\n",
    "    zero_division=0\n",
    "))\n",
    "cm = confusion_matrix(y_true, y_pred_classes, labels=labels)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=target_names,\n",
    "            yticklabels=target_names)\n",
    "plt.title('Matriz de Confusi√≥n - MobileNetV2')\n",
    "plt.ylabel('Verdaderos')\n",
    "plt.xlabel('Predicciones')\n",
    "plt.savefig('output/MobileNetV2_confusion_matrix.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"\\nEntrenamiento y evaluaci√≥n MobileNetV2 completados!\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
