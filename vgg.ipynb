{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. librer√≠as necesarias para construir, entrenar y evaluar el modelo CNN VGG16, adem√°s de herramientas para manejo de datos, visualizaci√≥n y m√©tricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Definicion de hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = (128, 224)\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 20\n",
    "LR_VGG = 1e-5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. verficacion de rutas de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "base_dir = 'data/dataset'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "val_dir = os.path.join(base_dir, 'val')\n",
    "test_dir = os.path.join(base_dir, 'test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Detecion automatica de clases "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def get_classes_from_directory(directory):\n",
    "    return sorted([\n",
    "        d for d in os.listdir(directory)\n",
    "        if os.path.isdir(os.path.join(directory, d)) and not d.startswith('.')\n",
    "    ])\n",
    "\n",
    "CLASSES = get_classes_from_directory(train_dir)\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "\n",
    "print(CLASSES)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Aumentacion de datos para entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=25,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.7, 1.3],\n",
    "    channel_shift_range=30.0,\n",
    "    fill_mode='nearest',\n",
    "    dtype='float32'\n",
    ")\n",
    "\n",
    "val_test_datagen = ImageDataGenerator(rescale=1./255, dtype='float32')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train_datagen = ImageDataGGenerator(..)\n",
    "\n",
    "este generador solo usa el cojunto den entrenamiento\n",
    "\n",
    "Argumentos utilizados: \n",
    "\n",
    "| Par√°metro                     | Descripci√≥n                                                                                                   |\n",
    "| ----------------------------- | ------------------------------------------------------------------------------------------------------------- |\n",
    "| `rescale=1./255`              | Escala los p√≠xeles de \\[0, 255] a \\[0, 1], necesario para redes neuronales.                                   |\n",
    "| `rotation_range=25`           | Gira la imagen aleatoriamente entre -25¬∞ y 25¬∞.                                                               |\n",
    "| `width_shift_range=0.2`       | Desplaza la imagen horizontalmente hasta un 20% del ancho.                                                    |\n",
    "| `height_shift_range=0.2`      | Desplaza la imagen verticalmente hasta un 20% de la altura.                                                   |\n",
    "| `shear_range=0.15`            | Aplica una distorsi√≥n en forma de cizalla (shear), inclinando la imagen.                                      |\n",
    "| `zoom_range=0.2`              | Aplica zoom aleatorio hasta un 20% m√°s o menos.                                                               |\n",
    "| `horizontal_flip=True`        | Voltea horizontalmente la imagen (izquierda/derecha), √∫til para simetr√≠a.                                     |\n",
    "| `brightness_range=[0.7, 1.3]` | Ajusta el brillo aleatoriamente entre 70% y 130%.                                                             |\n",
    "| `channel_shift_range=30.0`    | Cambia aleatoriamente los valores de los canales de color (RGB) hasta ¬±30 unidades.                           |\n",
    "| `fill_mode='nearest'`         | Cuando se hace una transformaci√≥n que genera espacios vac√≠os, los rellena con el valor del p√≠xel m√°s cercano. |\n",
    "| `dtype='float32'`             | El tipo de datos que va a tener cada imagen generada (por defecto es `float32`).                              |\n",
    "\n",
    "\n",
    "\n",
    "basicamente lo que hace toma una imagen original y crea nuevas versiones modificadas aleatoriamente en cada epoca del entranamiento.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## val_test_datagen = ImageDataGenerator(..)\n",
    "\n",
    "este lo utilizamos para validacion y test . no aplicamos ningun tipo de aumento, ya que no queremos alterar los datos al evaluar el rendimiento del modelo \n",
    "\n",
    "1. rescale=1/255 -> normaliza los pixeles\n",
    "\n",
    "2. dtype='float32' -> mismo tipo de dato del anterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Generadores de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    classes=CLASSES\n",
    ")\n",
    "\n",
    "val_generator = val_test_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    classes=CLASSES\n",
    ")\n",
    "\n",
    "test_generator = val_test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    "    classes=CLASSES\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "esta porcion de codigo leen las imagenes de disco , le asginana etiquetas segun la clase que es, la transforma y la entraga en lotes a la red neuronal para el entrenamiento la validacion y el testeo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Calculo de pesos por clase para balancear el entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class_weights_array = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_generator.classes),\n",
    "    y=train_generator.classes\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights_array))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este c√≥digo calcula pesos para cada clase seg√∫n su frecuencia en los datos de entrenamiento, de forma que las clases menos frecuentes tengan un peso mayor. Esto ayuda a que el modelo no se sesgue hacia las clases m√°s comunes.\n",
    "\n",
    "1. compute_class_weight con 'balanced' genera esos pesos autom√°ticamente.\n",
    "\n",
    "2. class_weights es un diccionario {clase: peso} que luego se usa en el entrenamiento para darle m√°s importancia a las clases minoritarias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Construccion del modelo VGG16 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "base_model = VGG16(\n",
    "    weights='imagenet', \n",
    "    include_top=False, # quitamos la capa final de clasificacion \n",
    "    input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)) \n",
    "base_model.trainable = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "se carga el modelo preentrenado (sin la capa de clasificacion final) con pesos de imageNet. congelamos la capa convulacional para usarlo como extratctor de caracteristicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu', kernel_regularizer='l2')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "outputs = Dense(NUM_CLASSES, activation='softmax')(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. creamos un tensor de entrada con la forma de la imagen \n",
    "\n",
    "2. pasamos esa entrada por el modelo base para extraer las caractetitsitcas \n",
    "\n",
    "3. aplicamos **GolbalAvergaePooling** para convertir el mapa de caracteristicas 2d un en vector 1D para poder pasarla a la capa siguiente\n",
    "\n",
    "4. tenemos una capa densa con 256 con relu con regularizacion L2\n",
    "\n",
    "5. aplicamos Droput con tasa 0.5 para desactivar aletoriamete 50% de la neuronas durante el entrenamiento \n",
    "\n",
    "6. creamos la capa de salida con **NUM_CLASSES** neuronaes, con activacion softmaz para multiclase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model = Model(inputs, outputs, name=\"VGG16\")  # creamos el modelo completo con entrada y salida definida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compilo el modelo con : \n",
    "\n",
    "1. optimizador Adam\n",
    "\n",
    "2. la funcion de perdida es entropia cruzada \n",
    "\n",
    "3. metrica principal es el **accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=LR_VGG),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ![Descripci√≥n de la imagen](./img/tl_vgg16.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OBS: SOLOS LAS DOS CAPAS DENSE SON ENTRENABLES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.  Callbacks para control del entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(patience=4, restore_best_weights=True, verbose=1),\n",
    "    ReduceLROnPlateau(factor=0.2, patience=2, verbose=1),\n",
    "    ModelCheckpoint('output/best_vgg.h5', save_best_only=True, monitor='val_accuracy'),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. EarlyStopping\n",
    "\n",
    "    - Funci√≥n: Detiene el entrenamiento si no mejora durante 4 √©pocas.\n",
    "\n",
    "    - Ventaja: Evita el sobreentrenamiento y ahorra tiempo.\n",
    "\n",
    "    - restore_best_weights=True: Recupera los mejores pesos al final.\n",
    "\n",
    "2. ReduceLROnPlateau\n",
    "\n",
    "    - Funci√≥n: Reduce el learning rate si no mejora en 2 √©pocas.\n",
    "\n",
    "    - Ventaja: Permite ajustes finos al estancarse el modelo.\n",
    "\n",
    "    - factor=0.2: Reduce el LR al 20% del actual.\n",
    "\n",
    "3. ModelCheckpoint\n",
    "\n",
    "    - Funci√≥n: Guarda el modelo cada vez que mejora la precisi√≥n en validaci√≥n (val_accuracy).\n",
    "\n",
    "    - Ventaja: Conserva autom√°ticamente la mejor versi√≥n del modelo.\n",
    "\n",
    "    - save_best_only=True: Solo guarda si mejora respecto al anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Entranamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\\\nEntrenando VGG16...\")\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=callbacks,\n",
    "    class_weight=class_weights,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11 . Visualizacion, Prediccion y evaluacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# üîÆ PREDICCI√ìN Y EVALUACI√ìN FINAL\n",
    "# ===============================\n",
    "\n",
    "# 1. Realiza predicciones sobre el conjunto de prueba\n",
    "y_pred = model.predict(test_generator)\n",
    "\n",
    "# 2. Convierte las probabilidades (softmax) en clases predichas (√≠ndices)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# 3. Extrae las clases verdaderas del generador\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# 4. Obtiene los nombres de las clases\n",
    "labels = list(test_generator.class_indices.values())     # Ej: [0, 1, 2]\n",
    "target_names = list(test_generator.class_indices.keys()) # Ej: ['Commercial', 'Private',..]\n",
    "\n",
    "# 5. Imprime un reporte de clasificaci√≥n detallado\n",
    "print(\"\\nClassification Report for VGG16:\")\n",
    "print(classification_report(\n",
    "    y_true,               # etiquetas reales\n",
    "    y_pred_classes,       # etiquetas predichas\n",
    "    labels=labels,        # las clases como n√∫meros\n",
    "    target_names=target_names, # nombres de las clases\n",
    "    digits=4,             # mostrar 4 decimales\n",
    "    zero_division=0       # evitar error si una clase no fue predicha\n",
    "))\n",
    "\n",
    "# 6. Crea matriz de confusi√≥n\n",
    "cm = confusion_matrix(y_true, y_pred_classes, labels=labels)\n",
    "\n",
    "# 7. Grafica la matriz de confusi√≥n\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=target_names,\n",
    "            yticklabels=target_names)\n",
    "plt.title('Matriz de Confusi√≥n - VGG16')\n",
    "plt.ylabel('Verdaderos')\n",
    "plt.xlabel('Predicciones')\n",
    "plt.savefig('output/VGG16_confusion_matrix.png')  # Guarda la imagen\n",
    "plt.close()  # Cierra la figura para evitar sobrecarga\n",
    "\n",
    "# ===============================\n",
    "# üìà GR√ÅFICO DE ENTRENAMIENTO\n",
    "# ===============================\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Precisi√≥n\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Entrenamiento')\n",
    "plt.plot(history.history['val_accuracy'], label='Validaci√≥n')\n",
    "plt.title('Precisi√≥n - VGG16')\n",
    "plt.ylabel('Precisi√≥n')\n",
    "plt.xlabel('√âpoca')\n",
    "plt.legend()\n",
    "\n",
    "# P√©rdida\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Entrenamiento')\n",
    "plt.plot(history.history['val_loss'], label='Validaci√≥n')\n",
    "plt.title('P√©rdida - VGG16')\n",
    "plt.ylabel('P√©rdida')\n",
    "plt.xlabel('√âpoca')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/VGG16_history.png')  # Guarda los gr√°ficos de entrenamiento\n",
    "plt.close()\n",
    "\n",
    "# ===============================\n",
    "# ‚úÖ MENSAJE FINAL\n",
    "# ===============================\n",
    "print(\"\\nEntrenamiento y evaluaci√≥n VGG16 completados!\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
