{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. librerías necesarias para construir, entrenar y evaluar el modelo CNN VGG16, además de herramientas para manejo de datos, visualización y métricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Definicion de hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = (128, 224)\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 20\n",
    "LR_VGG = 1e-5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. verficacion de rutas de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "base_dir = 'data/dataset'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "val_dir = os.path.join(base_dir, 'val')\n",
    "test_dir = os.path.join(base_dir, 'test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Detecion automatica de clases "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def get_classes_from_directory(directory):\n",
    "    return sorted([\n",
    "        d for d in os.listdir(directory)\n",
    "        if os.path.isdir(os.path.join(directory, d)) and not d.startswith('.')\n",
    "    ])\n",
    "\n",
    "CLASSES = get_classes_from_directory(train_dir)\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "\n",
    "print(CLASSES)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Aumentacion de datos para entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=25,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.7, 1.3],\n",
    "    channel_shift_range=30.0,\n",
    "    fill_mode='nearest',\n",
    "    dtype='float32'\n",
    ")\n",
    "\n",
    "val_test_datagen = ImageDataGenerator(rescale=1./255, dtype='float32')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train_datagen = ImageDataGGenerator(..)\n",
    "\n",
    "este generador solo usa el cojunto den entrenamiento\n",
    "\n",
    "Argumentos utilizados: \n",
    "\n",
    "| Parámetro                     | Descripción                                                                                                   |\n",
    "| ----------------------------- | ------------------------------------------------------------------------------------------------------------- |\n",
    "| `rescale=1./255`              | Escala los píxeles de \\[0, 255] a \\[0, 1], necesario para redes neuronales.                                   |\n",
    "| `rotation_range=25`           | Gira la imagen aleatoriamente entre -25° y 25°.                                                               |\n",
    "| `width_shift_range=0.2`       | Desplaza la imagen horizontalmente hasta un 20% del ancho.                                                    |\n",
    "| `height_shift_range=0.2`      | Desplaza la imagen verticalmente hasta un 20% de la altura.                                                   |\n",
    "| `shear_range=0.15`            | Aplica una distorsión en forma de cizalla (shear), inclinando la imagen.                                      |\n",
    "| `zoom_range=0.2`              | Aplica zoom aleatorio hasta un 20% más o menos.                                                               |\n",
    "| `horizontal_flip=True`        | Voltea horizontalmente la imagen (izquierda/derecha), útil para simetría.                                     |\n",
    "| `brightness_range=[0.7, 1.3]` | Ajusta el brillo aleatoriamente entre 70% y 130%.                                                             |\n",
    "| `channel_shift_range=30.0`    | Cambia aleatoriamente los valores de los canales de color (RGB) hasta ±30 unidades.                           |\n",
    "| `fill_mode='nearest'`         | Cuando se hace una transformación que genera espacios vacíos, los rellena con el valor del píxel más cercano. |\n",
    "| `dtype='float32'`             | El tipo de datos que va a tener cada imagen generada (por defecto es `float32`).                              |\n",
    "\n",
    "\n",
    "\n",
    "basicamente lo que hace toma una imagen original y crea nuevas versiones modificadas aleatoriamente en cada epoca del entranamiento.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## val_test_datagen = ImageDataGenerator(..)\n",
    "\n",
    "este lo utilizamos para validacion y test . no aplicamos ningun tipo de aumento, ya que no queremos alterar los datos al evaluar el rendimiento del modelo \n",
    "\n",
    "1. rescale=1/255 -> normaliza los pixeles\n",
    "\n",
    "2. dtype='float32' -> mismo tipo de dato del anterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Generadores de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    classes=CLASSES\n",
    ")\n",
    "\n",
    "val_generator = val_test_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    classes=CLASSES\n",
    ")\n",
    "\n",
    "test_generator = val_test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    "    classes=CLASSES\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "esta porcion de codigo leen las imagenes de disco , le asginana etiquetas segun la clase que es, la transforma y la entraga en lotes a la red neuronal para el entrenamiento la validacion y el testeo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Calculo de pesos por clase para balancear el entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class_weights_array = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_generator.classes),\n",
    "    y=train_generator.classes\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights_array))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código calcula pesos para cada clase según su frecuencia en los datos de entrenamiento, de forma que las clases menos frecuentes tengan un peso mayor. Esto ayuda a que el modelo no se sesgue hacia las clases más comunes.\n",
    "\n",
    "1. compute_class_weight con 'balanced' genera esos pesos automáticamente.\n",
    "\n",
    "2. class_weights es un diccionario {clase: peso} que luego se usa en el entrenamiento para darle más importancia a las clases minoritarias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Construccion del modelo VGG16 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "base_model = VGG16(\n",
    "    weights='imagenet', \n",
    "    include_top=False, # quitamos la capa final de clasificacion \n",
    "    input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)) \n",
    "base_model.trainable = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "se carga el modelo preentrenado (sin la capa de clasificacion final) con pesos de imageNet. congelamos la capa convulacional para usarlo como extratctor de caracteristicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu', kernel_regularizer='l2')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "outputs = Dense(NUM_CLASSES, activation='softmax')(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. creamos un tensor de entrada con la forma de la imagen \n",
    "\n",
    "2. pasamos esa entrada por el modelo base para extraer las caractetitsitcas \n",
    "\n",
    "3. aplicamos **GolbalAvergaePooling** para convertir el mapa de caracteristicas 2d un en vector 1D para poder pasarla a la capa siguiente\n",
    "\n",
    "4. tenemos una capa densa con 256 con relu con regularizacion L2\n",
    "\n",
    "5. aplicamos Droput con tasa 0.5 para desactivar aletoriamete 50% de la neuronas durante el entrenamiento \n",
    "\n",
    "6. creamos la capa de salida con **NUM_CLASSES** neuronaes, con activacion softmaz para multiclase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model = Model(inputs, outputs, name=\"VGG16\")  # creamos el modelo completo con entrada y salida definida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compilo el modelo con : \n",
    "\n",
    "1. optimizador Adam\n",
    "\n",
    "2. la funcion de perdida es entropia cruzada \n",
    "\n",
    "3. metrica principal es el **accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=LR_VGG),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ![Descripción de la imagen](./img/tl_vgg16.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OBS: SOLOS LAS DOS CAPAS DENSE SON ENTRENABLES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.  Callbacks para control del entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(patience=4, restore_best_weights=True, verbose=1),\n",
    "    ReduceLROnPlateau(factor=0.2, patience=2, verbose=1),\n",
    "    ModelCheckpoint('output/best_vgg.h5', save_best_only=True, monitor='val_accuracy'),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. EarlyStopping\n",
    "\n",
    "    - Función: Detiene el entrenamiento si no mejora durante 4 épocas.\n",
    "\n",
    "    - Ventaja: Evita el sobreentrenamiento y ahorra tiempo.\n",
    "\n",
    "    - restore_best_weights=True: Recupera los mejores pesos al final.\n",
    "\n",
    "2. ReduceLROnPlateau\n",
    "\n",
    "    - Función: Reduce el learning rate si no mejora en 2 épocas.\n",
    "\n",
    "    - Ventaja: Permite ajustes finos al estancarse el modelo.\n",
    "\n",
    "    - factor=0.2: Reduce el LR al 20% del actual.\n",
    "\n",
    "3. ModelCheckpoint\n",
    "\n",
    "    - Función: Guarda el modelo cada vez que mejora la precisión en validación (val_accuracy).\n",
    "\n",
    "    - Ventaja: Conserva automáticamente la mejor versión del modelo.\n",
    "\n",
    "    - save_best_only=True: Solo guarda si mejora respecto al anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Entranamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\\\nEntrenando VGG16...\")\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=callbacks,\n",
    "    class_weight=class_weights,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11 . Visualizacion, Prediccion y evaluacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 🔮 PREDICCIÓN Y EVALUACIÓN FINAL\n",
    "# ===============================\n",
    "\n",
    "# 1. Realiza predicciones sobre el conjunto de prueba\n",
    "y_pred = model.predict(test_generator)\n",
    "\n",
    "# 2. Convierte las probabilidades (softmax) en clases predichas (índices)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# 3. Extrae las clases verdaderas del generador\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# 4. Obtiene los nombres de las clases\n",
    "labels = list(test_generator.class_indices.values())     # Ej: [0, 1, 2]\n",
    "target_names = list(test_generator.class_indices.keys()) # Ej: ['Commercial', 'Private',..]\n",
    "\n",
    "# 5. Imprime un reporte de clasificación detallado\n",
    "print(\"\\nClassification Report for VGG16:\")\n",
    "print(classification_report(\n",
    "    y_true,               # etiquetas reales\n",
    "    y_pred_classes,       # etiquetas predichas\n",
    "    labels=labels,        # las clases como números\n",
    "    target_names=target_names, # nombres de las clases\n",
    "    digits=4,             # mostrar 4 decimales\n",
    "    zero_division=0       # evitar error si una clase no fue predicha\n",
    "))\n",
    "\n",
    "# 6. Crea matriz de confusión\n",
    "cm = confusion_matrix(y_true, y_pred_classes, labels=labels)\n",
    "\n",
    "# 7. Grafica la matriz de confusión\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=target_names,\n",
    "            yticklabels=target_names)\n",
    "plt.title('Matriz de Confusión - VGG16')\n",
    "plt.ylabel('Verdaderos')\n",
    "plt.xlabel('Predicciones')\n",
    "plt.savefig('output/VGG16_confusion_matrix.png')  # Guarda la imagen\n",
    "plt.close()  # Cierra la figura para evitar sobrecarga\n",
    "\n",
    "# ===============================\n",
    "# 📈 GRÁFICO DE ENTRENAMIENTO\n",
    "# ===============================\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Precisión\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Entrenamiento')\n",
    "plt.plot(history.history['val_accuracy'], label='Validación')\n",
    "plt.title('Precisión - VGG16')\n",
    "plt.ylabel('Precisión')\n",
    "plt.xlabel('Época')\n",
    "plt.legend()\n",
    "\n",
    "# Pérdida\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Entrenamiento')\n",
    "plt.plot(history.history['val_loss'], label='Validación')\n",
    "plt.title('Pérdida - VGG16')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.xlabel('Época')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/VGG16_history.png')  # Guarda los gráficos de entrenamiento\n",
    "plt.close()\n",
    "\n",
    "# ===============================\n",
    "# ✅ MENSAJE FINAL\n",
    "# ===============================\n",
    "print(\"\\nEntrenamiento y evaluación VGG16 completados!\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
